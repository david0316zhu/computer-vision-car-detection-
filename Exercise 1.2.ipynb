{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd multi-object-tracker\n",
    "# from motrackers import CentroidTracker, IOUTracker, CentroidKF_Tracker, SORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 25:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Subtraction_Detector:\n",
    "    'This class for car detection'\n",
    "    def __init__(self, ):\n",
    "        self.first_frame = None\n",
    "    \n",
    "    def detect(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (5,5), 0) \n",
    "        \n",
    "        if self.first_frame is None:\n",
    "            self.first_frame = gray\n",
    "            return np.array([]).reshape(0,4)\n",
    "        \n",
    "        list_objects = []\n",
    "        \n",
    "        mask = cv2.absdiff(self.first_frame, gray)\n",
    "        mask = cv2.dilate(mask, np.ones((3,3)), iterations=3)\n",
    "        _, mask = cv2.threshold(mask, 15, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 6000:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                list_objects.append([x,y,w,h])\n",
    "        return np.array(list_objects)\n",
    "\n",
    "def is_in_track_region(region, c):\n",
    "    '''\n",
    "    region in order: [x1,y1,x2,y2]\n",
    "    c in order: [c_x, c_y]\n",
    "    '''\n",
    "    x1,y1,x2,y2 = region\n",
    "    return (x1 <= c[0] <= x2) and (y1 <= c[1] <= y2) \n",
    "\n",
    "def to_city(track_info, x_l, x_r):\n",
    "    \"\"\"\"\n",
    "    check car's direction to the city or not\n",
    "    \"\"\"\n",
    "    x,_,_ = track_info\n",
    "    return x_r - x < x - x_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(\"./Traffic_Laramie_1.mp4\")\n",
    "num_cars = 0\n",
    "detector = Subtraction_Detector()\n",
    "tracker = EuclideanDistTracker()\n",
    "bounding_x, bounding_y, bounding_w, bounding_h = 1,300,1035,300\n",
    "\n",
    "# track_dict to Track object in my rectangle region\n",
    "track_dict = {} \n",
    "tracking_region = [640, 30, 660, 300] # [x1,y1,x2,y2]\n",
    "frame_id = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    line_color = (0,0,130)\n",
    "    if not ret:\n",
    "        break\n",
    "    height, width, _ = frame.shape\n",
    "    roi = frame[300: 600,0: 1040]\n",
    "    cv2.putText(frame, 'Main road', (50, 290), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "    \n",
    "    list_objects = detector.detect(roi)\n",
    "    output_track = tracker.update(list_objects)\n",
    "\n",
    "    for track in output_track:\n",
    "        x1, y1, w, h, id = track\n",
    "        cv2.rectangle(roi,(x1,y1),(x1+w,y1+h),(0,255,0),2)\n",
    "        #cv2.putText(roi, f'car: {id}', (x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0,0,255), 2)\n",
    "        \n",
    "        cx,cy = int((2*x1 + w)/2), int((2*y1+h)/2)\n",
    "        cv2.circle(roi, (cx,cy), 5, (0,0,255), -1)\n",
    "        if is_in_track_region(tracking_region, (cx,cy)):\n",
    "            track_dict[id] = track_dict.get(id, []) + [(cx,cy, frame_id)]\n",
    "        \n",
    "    \n",
    "    out_keys = [k for k, v in track_dict.items() if v[-1][2] != frame_id]\n",
    "    for k in out_keys:\n",
    "        if to_city(track_info=track_dict[k][0], x_l=tracking_region[0], x_r=tracking_region[2]):\n",
    "            num_cars += 1\n",
    "            line_color = (0,0,255)\n",
    "        del track_dict[k]\n",
    "    \n",
    "    cv2.rectangle(frame, (bounding_x, bounding_y), (bounding_x + bounding_w, bounding_y + bounding_h), (0,0,255), 2)\n",
    "    cv2.line(roi, (tracking_region[0], tracking_region[1]), (tracking_region[0], tracking_region[3]), line_color, 5)\n",
    "    cv2.putText(frame, f'frame: {frame_id}', (0,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    cv2.putText(frame, f'num cars: {num_cars}', (width-150, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0,0,255), 1)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "    frame_id += 1\n",
    "    print(f'num_cars: {num_cars}')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(num_cars)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cap = cv2.VideoCapture(\"../Traffic_Laramie_1.mp4\")\n",
    "# num_cars = 0\n",
    "# detector = Subtraction_Detector()\n",
    "# tracker = CentroidKF_Tracker()\n",
    "# bounding_x, bounding_y, bounding_w, bounding_h = 1,300,1035,300\n",
    "# track_dict = {}\n",
    "# tracking_region = [640, 30, 660, 300] # [x1,y1,x2,y2]\n",
    "# frame_id = 0\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     line_color = (0,0,130)\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     height, width, _ = frame.shape\n",
    "#     roi = frame[300: 600,0: 1040]\n",
    "    \n",
    "#     list_objects = detector.detect(roi)\n",
    "#     output_track = tracker.update(list_objects, np.ones(len(list_objects), np.ones(len(list_objects))))\n",
    "\n",
    "#     for track in output_track:\n",
    "#         _, id, x1, y1, w, h, _, _, _, _ = track\n",
    "#         cv2.rectangle(roi,(x1,y1),(x1+w,y1+h),(0,255,0),2)\n",
    "#         cv2.putText(roi, str(id), (x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        \n",
    "#         cx,cy = int((2*x1 + w)/2), int((2*y1+h)/2)\n",
    "#         cv2.circle(roi, (cx,cy), 5, (0,0,255), -1)\n",
    "#         if is_in_track_region(tracking_region, (cx,cy)):\n",
    "#             track_dict[id] = track_dict.get(id, []) + [(cx,cy, frame_id)]\n",
    "        \n",
    "    \n",
    "#     out_keys = [k for k, v in track_dict.items() if v[-1][2] != frame_id]\n",
    "#     for k in out_keys:\n",
    "#         if to_city(track_info=track_dict[k][0], x_l=tracking_region[0], x_r=tracking_region[2]):\n",
    "#             num_cars += 1\n",
    "#             line_color = (0,0,255)\n",
    "#         del track_dict[k]\n",
    "    \n",
    "#     cv2.rectangle(frame, (bounding_x, bounding_y), (bounding_x + bounding_w, bounding_y + bounding_h), (0,0,255), 1)\n",
    "#     cv2.line(roi, (tracking_region[0], tracking_region[1]), (tracking_region[0], tracking_region[3]), line_color, 5)\n",
    "#     cv2.putText(frame, f'car: {frame_id}', (0,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "#     cv2.putText(frame, f'num cars: {num_cars}', (width-150, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,255), 1)\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "#     key = cv2.waitKey(30)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "    \n",
    "#     frame_id += 1\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
